{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train Models\n",
    "<div style=\"color:red; font-size:14px;\">!! Don't define functions here, import them from utils.py</div>\n",
    "\n",
    "This notebook contains the code needed to train and store models to disk.\n",
    "\n",
    "Remember that if you use a function with a random state you have to fix it to a number so that the results are reproducible."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling skseq/sequence_list_c.pyx because it changed.\r\n",
      "[1/1] Cythonizing skseq/sequence_list_c.pyx\r\n",
      "/opt/anaconda3/envs/master/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/davidrosado/Documents/named-entity-recognition/skseq/sequence_list_c.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "running build_ext\r\n",
      "building 'sequence_list_c' extension\r\n",
      "clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/anaconda3/envs/master/include -arch x86_64 -I/opt/anaconda3/envs/master/include -fPIC -O2 -isystem /opt/anaconda3/envs/master/include -arch x86_64 -I/opt/anaconda3/envs/master/include/python3.9 -c skseq/sequence_list_c.c -o build/temp.macosx-10.9-x86_64-cpython-39/skseq/sequence_list_c.o\r\n",
      "\u001B[1mskseq/sequence_list_c.c:7783:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\r\n",
      "                    CYTHON_FALLTHROUGH;\r\n",
      "\u001B[0;1;32m                    ^\r\n",
      "\u001B[0m\u001B[1mskseq/sequence_list_c.c:296:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\r\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\r\n",
      "\u001B[0;1;32m                                 ^\r\n",
      "\u001B[0m\u001B[1mskseq/sequence_list_c.c:7794:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\r\n",
      "                    CYTHON_FALLTHROUGH;\r\n",
      "\u001B[0;1;32m                    ^\r\n",
      "\u001B[0m\u001B[1mskseq/sequence_list_c.c:296:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\r\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\r\n",
      "\u001B[0;1;32m                                 ^\r\n",
      "\u001B[0m2 warnings generated.\r\n",
      "clang -bundle -undefined dynamic_lookup -Wl,-rpath,/opt/anaconda3/envs/master/lib -L/opt/anaconda3/envs/master/lib -L/opt/anaconda3/envs/master/lib -Wl,-rpath,/opt/anaconda3/envs/master/lib -L/opt/anaconda3/envs/master/lib build/temp.macosx-10.9-x86_64-cpython-39/skseq/sequence_list_c.o -o ./skseq/sequence_list_c.cpython-39-darwin.so\r\n"
     ]
    }
   ],
   "source": [
    "# Cython import\n",
    "!python skseq/setup.py build_ext --build-lib=./skseq"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from skseq.id_feature import IDFeatures\n",
    "from skseq.extended_feature import ExtendedFeatures\n",
    "from skseq.structured_perceptron import StructuredPerceptron\n",
    "\n",
    "from utils.utils import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Train and Test sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_data_ner.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 38366/38366 [00:38<00:00, 1005.73sentence/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_data_target_sets(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Corpus\n",
    "\n",
    "We need to create our corpus using the training data. The corpus consists of two dictionaries, one for the words and one for the tags. The words dictionary maps each word to an index and the tags dictionary maps each tag to an index. We also need to create the reverse mapping for the tags dictionary. This is needed to convert the predictions back to the tag names.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "        sentences = [['I', 'love', 'Python'], ['Python', 'is', 'great']]\n",
    "        tags = ['O', 'O', 'B']\n",
    "        word_dict, tag_dict, tag_dict_rev = create_corpus(sentences, tags)\n",
    "        # word_dict: {'I': 0, 'love': 1, 'Python': 2, 'is': 3, 'great': 4}\n",
    "        # tag_dict: {'O': 0, 'B': 1}\n",
    "        # tag_dict_rev: {0: 'O', 1: 'B'}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "word_dict, tag_dict, tag_dict_rev = create_corpus(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Training Sequence List"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding sequences:  65%|██████▍   | 24851/38366 [03:31<01:55, 117.51sequence/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/nc/wbbw2w1x72dg89nnx4p_1xwr0000gn/T/ipykernel_47695/692216385.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain_seq\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_sequence_list\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mword_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtag_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/named-entity-recognition/utils/utils.py\u001B[0m in \u001B[0;36mcreate_sequence_list\u001B[0;34m(word_dict, tag_dict, X, y)\u001B[0m\n\u001B[1;32m     98\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mprogress_bar\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     99\u001B[0m         \u001B[0;31m# Add the sequence (X[i], y[i]) to the sequence list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 100\u001B[0;31m         \u001B[0mseq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_sequence\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mLabelDictionary\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mword_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mLabelDictionary\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtag_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mseq\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/named-entity-recognition/skseq/label_dictionary.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, label_names)\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnames\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlabel_names\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/named-entity-recognition/skseq/label_dictionary.py\u001B[0m in \u001B[0;36madd\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m             \u001B[0mwarnings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwarn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Ignoring duplicated label '\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabel_id\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnames\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mlabel_id\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_seq = create_sequence_list(word_dict, tag_dict, X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/0 1/0 2/0 3/0 4/0 5/0 6/1 7/0 8/0 9/0 10/0 11/0 12/1 13/0 14/0 9/0 15/0 1/0 16/2 17/0 18/0 19/0 20/0 21/0 \n",
      "U.N./B-geo relief/O coordinator/O Jan/B-per Egeland/I-per said/O Sunday/B-tim ,/O U.S./B-geo ,/O Indonesian/B-gpe and/O Australian/B-gpe military/O helicopters/O are/O ferrying/O out/O food/O and/O supplies/O to/O remote/O areas/O of/O western/O Aceh/B-geo province/O that/O ground/O crews/O can/O not/O reach/O ./O \n"
     ]
    }
   ],
   "source": [
    "print(train_seq[0])\n",
    "print(train_seq[3].to_words(sequence_list=train_seq))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert\" style=\"padding: 20px;background-color: #2cbc84; color: white; margin-bottom: 15px;\">\n",
    "<h3>Structured Perceptron w/ Default Features</h3>\n",
    "</div>\n",
    "\n",
    "To train the structured perceptron we must create a feature mapper and build it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "feature_mapper = IDFeatures(train_seq)\n",
    "feature_mapper.build_features()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features\n",
      "[0] init_tag:O\n",
      "\n",
      "\n",
      "Transition features\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[9] prev_tag:O::B-geo\n",
      "[11] prev_tag:B-geo::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[9] prev_tag:O::B-geo\n",
      "[11] prev_tag:B-geo::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[21] prev_tag:O::B-gpe\n",
      "[23] prev_tag:B-gpe::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "[3] prev_tag:O::O\n",
      "\n",
      "\n",
      "Final features\n",
      "[28] final_prev_tag:O\n",
      "\n",
      "\n",
      "Emission features\n",
      "[1] id:Thousands::O\n",
      "[2] id:of::O\n",
      "[4] id:demonstrators::O\n",
      "[5] id:have::O\n",
      "[6] id:marched::O\n",
      "[7] id:through::O\n",
      "[8] id:London::B-geo\n",
      "[10] id:to::O\n",
      "[12] id:protest::O\n",
      "[13] id:the::O\n",
      "[14] id:war::O\n",
      "[15] id:in::O\n",
      "[16] id:Iraq::B-geo\n",
      "[17] id:and::O\n",
      "[18] id:demand::O\n",
      "[13] id:the::O\n",
      "[19] id:withdrawal::O\n",
      "[2] id:of::O\n",
      "[20] id:British::B-gpe\n",
      "[22] id:troops::O\n",
      "[24] id:from::O\n",
      "[25] id:that::O\n",
      "[26] id:country::O\n",
      "[27] id:.::O\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_features(feature_mapper, train_seq[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.893815\n",
      "Epoch: 1 Accuracy: 0.931674\n",
      "Epoch: 2 Accuracy: 0.940913\n",
      "Epoch: 3 Accuracy: 0.946175\n",
      "Epoch: 4 Accuracy: 0.950018\n",
      "Epoch: 5 Accuracy: 0.952577\n",
      "Epoch: 6 Accuracy: 0.954425\n",
      "Epoch: 7 Accuracy: 0.956033\n",
      "Epoch: 8 Accuracy: 0.957185\n",
      "Epoch: 9 Accuracy: 0.958481\n",
      "Epoch: 10 Accuracy: 0.959217\n",
      "Epoch: 11 Accuracy: 0.960524\n",
      "Epoch: 12 Accuracy: 0.961121\n",
      "Epoch: 13 Accuracy: 0.961207\n",
      "Epoch: 14 Accuracy: 0.961983\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "sp = StructuredPerceptron(word_dict, tag_dict, feature_mapper)\n",
    "sp.num_epochs = 5\n",
    "sp.fit(feature_mapper.dataset, num_epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "sp.save_model(\"fitted_models/01_SP_Default_Features\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert\" style=\"padding: 20px;background-color: #2cbc84; color: white; margin-bottom: 15px;\">\n",
    "<h3>Structured Perceptron w/ New Features</h3>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "feature_mapper_ext = ExtendedFeatures(train_seq)\n",
    "feature_mapper_ext.build_features()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features\n",
      "[0] init_tag:O\n",
      "\n",
      "\n",
      "Transition features\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[14] prev_tag:O::B-geo\n",
      "[16] prev_tag:B-geo::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[14] prev_tag:O::B-geo\n",
      "[16] prev_tag:B-geo::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[28] prev_tag:O::B-gpe\n",
      "[30] prev_tag:B-gpe::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "[6] prev_tag:O::O\n",
      "\n",
      "\n",
      "Final features\n",
      "[35] final_prev_tag:O\n",
      "\n",
      "\n",
      "Emission features\n",
      "[1, 2, 3] id:Thousands::O\n",
      "[1, 2, 3] firstupper::O\n",
      "[1, 2, 3] alphanum::O\n",
      "[4, 5, 3] id:of::O\n",
      "[4, 5, 3] lower::O\n",
      "[4, 5, 3] alphanum::O\n",
      "[7, 5, 3] id:demonstrators::O\n",
      "[7, 5, 3] lower::O\n",
      "[7, 5, 3] alphanum::O\n",
      "[8, 5, 3] id:have::O\n",
      "[8, 5, 3] lower::O\n",
      "[8, 5, 3] alphanum::O\n",
      "[9, 5, 3] id:marched::O\n",
      "[9, 5, 3] lower::O\n",
      "[9, 5, 3] alphanum::O\n",
      "[10, 5, 3] id:through::O\n",
      "[10, 5, 3] lower::O\n",
      "[10, 5, 3] alphanum::O\n",
      "[11, 12, 13] id:London::B-geo\n",
      "[11, 12, 13] firstupper::B-geo\n",
      "[11, 12, 13] alphanum::B-geo\n",
      "[15, 5, 3] id:to::O\n",
      "[15, 5, 3] lower::O\n",
      "[15, 5, 3] alphanum::O\n",
      "[17, 5, 3] id:protest::O\n",
      "[17, 5, 3] lower::O\n",
      "[17, 5, 3] alphanum::O\n",
      "[18, 5, 3] id:the::O\n",
      "[18, 5, 3] lower::O\n",
      "[18, 5, 3] alphanum::O\n",
      "[19, 5, 3] id:war::O\n",
      "[19, 5, 3] lower::O\n",
      "[19, 5, 3] alphanum::O\n",
      "[20, 5, 3] id:in::O\n",
      "[20, 5, 3] lower::O\n",
      "[20, 5, 3] alphanum::O\n",
      "[21, 12, 13] id:Iraq::B-geo\n",
      "[21, 12, 13] firstupper::B-geo\n",
      "[21, 12, 13] alphanum::B-geo\n",
      "[22, 5, 3] id:and::O\n",
      "[22, 5, 3] lower::O\n",
      "[22, 5, 3] alphanum::O\n",
      "[23, 5, 3] id:demand::O\n",
      "[23, 5, 3] lower::O\n",
      "[23, 5, 3] alphanum::O\n",
      "[18, 5, 3] id:the::O\n",
      "[18, 5, 3] lower::O\n",
      "[18, 5, 3] alphanum::O\n",
      "[24, 5, 3] id:withdrawal::O\n",
      "[24, 5, 3] lower::O\n",
      "[24, 5, 3] alphanum::O\n",
      "[4, 5, 3] id:of::O\n",
      "[4, 5, 3] lower::O\n",
      "[4, 5, 3] alphanum::O\n",
      "[25, 26, 27] id:British::B-gpe\n",
      "[25, 26, 27] firstupper::B-gpe\n",
      "[25, 26, 27] alphanum::B-gpe\n",
      "[29, 5, 3] id:troops::O\n",
      "[29, 5, 3] lower::O\n",
      "[29, 5, 3] alphanum::O\n",
      "[31, 5, 3] id:from::O\n",
      "[31, 5, 3] lower::O\n",
      "[31, 5, 3] alphanum::O\n",
      "[32, 5, 3] id:that::O\n",
      "[32, 5, 3] lower::O\n",
      "[32, 5, 3] alphanum::O\n",
      "[33, 5, 3] id:country::O\n",
      "[33, 5, 3] lower::O\n",
      "[33, 5, 3] alphanum::O\n",
      "[34] id:.::O\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_features(feature_mapper_ext, train_seq[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.929235\n",
      "Epoch: 1 Accuracy: 0.944526\n",
      "Epoch: 2 Accuracy: 0.948609\n",
      "Epoch: 3 Accuracy: 0.951267\n",
      "Epoch: 4 Accuracy: 0.953126\n",
      "Epoch: 5 Accuracy: 0.954476\n",
      "Epoch: 6 Accuracy: 0.955556\n",
      "Epoch: 7 Accuracy: 0.956719\n",
      "Epoch: 8 Accuracy: 0.957269\n",
      "Epoch: 9 Accuracy: 0.958295\n",
      "Epoch: 10 Accuracy: 0.958931\n",
      "Epoch: 11 Accuracy: 0.959925\n",
      "Epoch: 12 Accuracy: 0.960049\n",
      "Epoch: 13 Accuracy: 0.960416\n",
      "Epoch: 14 Accuracy: 0.961072\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "sp_ext = StructuredPerceptron(word_dict, tag_dict, feature_mapper_ext)\n",
    "sp_ext.num_epochs = 5\n",
    "sp_ext.fit(feature_mapper_ext.dataset, num_epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "sp_ext.save_model(\"fitted_models/02_SP_Extended_Features\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
